{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YouTube Video Performance Analysis with K-Means Clustering\n",
    "\n",
    "This notebook analyzes YouTube video performance data to:\n",
    "1. Identify best and worst performing videos\n",
    "2. Understand factors contributing to performance\n",
    "3. Discover trending keywords and topics\n",
    "4. Use k-means clustering to group similar videos\n",
    "\n",
    "## Data Sources\n",
    "- `Chart data.csv` - Time-series view data per video\n",
    "- `Totals.csv` - Aggregated daily totals\n",
    "- `table data.csv` - Video-level performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load datasets\n",
    "chart_data = pd.read_csv('Chart data.csv')\n",
    "totals = pd.read_csv('Totals.csv')\n",
    "table_data = pd.read_csv('table data.csv')\n",
    "\n",
    "print(\"Dataset shapes:\")\n",
    "print(f\"Chart data: {chart_data.shape}\")\n",
    "print(f\"Totals: {totals.shape}\")\n",
    "print(f\"Table data: {table_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Display table data structure (most useful for clustering)\n",
    "print(\"\\nTable Data Columns:\")\n",
    "print(table_data.columns.tolist())\n",
    "print(\"\\nFirst few rows:\")\n",
    "table_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values in table data:\")\n",
    "print(table_data.isnull().sum())\n",
    "\n",
    "# Basic statistics\n",
    "print(\"\\nBasic statistics:\")\n",
    "table_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Clean the data - remove the 'Total' row if it exists\n",
    "df = table_data[table_data['Content'] != 'Total'].copy()\n",
    "\n",
    "# Convert date columns\n",
    "df['Video publish time'] = pd.to_datetime(df['Video publish time'])\n",
    "\n",
    "# Calculate days since publication\n",
    "today = datetime.now()\n",
    "df['days_since_publish'] = (today - df['Video publish time']).dt.days\n",
    "\n",
    "# Calculate derived metrics\n",
    "df['avg_view_duration'] = (df['Watch time (hours)'] * 60 / df['Views']).fillna(0)  # minutes\n",
    "df['views_per_day'] = df['Views'] / df['days_since_publish']\n",
    "df['revenue_per_view'] = df['Estimated revenue (GBP)'] / df['Views']\n",
    "df['subscriber_conversion'] = df['Subscribers'] / df['Views'] * 100\n",
    "df['clicks_per_impression'] = df['Impressions click-through rate (%)']\n",
    "\n",
    "# Handle infinite values\n",
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "df = df.fillna(0)\n",
    "\n",
    "print(f\"Cleaned dataset shape: {df.shape}\")\n",
    "print(f\"Total unique videos: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extract Keywords from Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Extract keywords from video titles\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# Common stop words to exclude\n",
    "stop_words = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', \n",
    "              'of', 'with', 'by', 'from', 'up', 'about', 'into', 'through', 'during',\n",
    "              'your', 'you', 'how', 'is', 'it', 'this', 'that', 'are', 'as', 'be'}\n",
    "\n",
    "def extract_keywords(title):\n",
    "    \"\"\"Extract meaningful keywords from title\"\"\"\n",
    "    # Convert to lowercase and split\n",
    "    words = re.findall(r'\\b[a-z]+\\b', title.lower())\n",
    "    # Filter out stop words and short words\n",
    "    keywords = [w for w in words if w not in stop_words and len(w) > 2]\n",
    "    return keywords\n",
    "\n",
    "# Extract all keywords\n",
    "all_keywords = []\n",
    "for title in df['Video title']:\n",
    "    all_keywords.extend(extract_keywords(str(title)))\n",
    "\n",
    "# Count keyword frequency\n",
    "keyword_counts = Counter(all_keywords)\n",
    "print(\"Top 30 keywords across all videos:\")\n",
    "for keyword, count in keyword_counts.most_common(30):\n",
    "    print(f\"{keyword}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Add keywords to dataframe\n",
    "df['keywords'] = df['Video title'].apply(lambda x: extract_keywords(str(x)))\n",
    "df['keyword_string'] = df['keywords'].apply(lambda x: ', '.join(x))\n",
    "\n",
    "# Create binary columns for top keywords\n",
    "top_keywords = [kw for kw, count in keyword_counts.most_common(20)]\n",
    "for keyword in top_keywords:\n",
    "    df[f'has_{keyword}'] = df['keywords'].apply(lambda x: 1 if keyword in x else 0)\n",
    "\n",
    "print(f\"\\nAdded {len(top_keywords)} keyword features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyze Trending Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Define recent videos (published in last 6 months)\n",
    "six_months_ago = today - timedelta(days=180)\n",
    "recent_videos = df[df['Video publish time'] > six_months_ago].copy()\n",
    "\n",
    "print(f\"Total videos: {len(df)}\")\n",
    "print(f\"Recent videos (last 6 months): {len(recent_videos)}\")\n",
    "\n",
    "# Extract keywords from recent videos\n",
    "recent_keywords = []\n",
    "for title in recent_videos['Video title']:\n",
    "    recent_keywords.extend(extract_keywords(str(title)))\n",
    "\n",
    "recent_keyword_counts = Counter(recent_keywords)\n",
    "\n",
    "# Calculate trending score (recent frequency vs overall frequency)\n",
    "trending_scores = {}\n",
    "for keyword in recent_keyword_counts:\n",
    "    if keyword in keyword_counts and keyword_counts[keyword] >= 3:  # Must appear at least 3 times overall\n",
    "        overall_freq = keyword_counts[keyword] / len(df)\n",
    "        recent_freq = recent_keyword_counts[keyword] / len(recent_videos)\n",
    "        trending_scores[keyword] = recent_freq / overall_freq if overall_freq > 0 else 0\n",
    "\n",
    "# Sort by trending score\n",
    "trending_keywords = sorted(trending_scores.items(), key=lambda x: x[1], reverse=True)[:20]\n",
    "\n",
    "print(\"\\nTrending Keywords (higher score = more popular recently):\")\n",
    "for keyword, score in trending_keywords:\n",
    "    overall_count = keyword_counts[keyword]\n",
    "    recent_count = recent_keyword_counts[keyword]\n",
    "    print(f\"{keyword}: Trending Score={score:.2f} (Overall: {overall_count}, Recent: {recent_count})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize trending keywords\n",
    "trending_df = pd.DataFrame(trending_keywords, columns=['Keyword', 'Trending Score'])\n",
    "trending_df = trending_df.head(15)\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.barh(trending_df['Keyword'], trending_df['Trending Score'], color='steelblue')\n",
    "plt.xlabel('Trending Score (Recent Popularity / Overall Popularity)')\n",
    "plt.title('Top Trending Keywords (Last 6 Months)')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Performance Analysis - Best and Worst Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Define composite performance score\n",
    "# Normalize metrics to 0-1 scale\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "performance_metrics = ['Views', 'Watch time (hours)', 'Subscribers', \n",
    "                       'Estimated revenue (GBP)', 'Impressions click-through rate (%)',\n",
    "                       'views_per_day', 'subscriber_conversion']\n",
    "\n",
    "df_scaled = df.copy()\n",
    "df_scaled[performance_metrics] = scaler.fit_transform(df[performance_metrics])\n",
    "\n",
    "# Calculate composite performance score (weighted average)\n",
    "weights = {\n",
    "    'Views': 0.25,\n",
    "    'Watch time (hours)': 0.20,\n",
    "    'Subscribers': 0.15,\n",
    "    'Estimated revenue (GBP)': 0.15,\n",
    "    'Impressions click-through rate (%)': 0.10,\n",
    "    'views_per_day': 0.10,\n",
    "    'subscriber_conversion': 0.05\n",
    "}\n",
    "\n",
    "df['performance_score'] = sum(df_scaled[metric] * weight \n",
    "                               for metric, weight in weights.items())\n",
    "\n",
    "# Sort by performance\n",
    "df_sorted = df.sort_values('performance_score', ascending=False)\n",
    "\n",
    "print(\"Top 10 Best Performing Videos:\")\n",
    "print(\"=\"*100)\n",
    "top_10 = df_sorted.head(10)[['Video title', 'Views', 'Watch time (hours)', \n",
    "                               'Subscribers', 'performance_score']]\n",
    "for idx, row in top_10.iterrows():\n",
    "    print(f\"\\n{row['Video title'][:80]}\")\n",
    "    print(f\"  Views: {row['Views']:,} | Watch Time: {row['Watch time (hours)']:.1f}h | \"\n",
    "          f\"Subscribers: {row['Subscribers']:,} | Score: {row['performance_score']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"\\n\\nBottom 10 Worst Performing Videos:\")\n",
    "print(\"=\"*100)\n",
    "bottom_10 = df_sorted.tail(10)[['Video title', 'Views', 'Watch time (hours)', \n",
    "                                  'Subscribers', 'performance_score']]\n",
    "for idx, row in bottom_10.iterrows():\n",
    "    print(f\"\\n{row['Video title'][:80]}\")\n",
    "    print(f\"  Views: {row['Views']:,} | Watch Time: {row['Watch time (hours)']:.1f}h | \"\n",
    "          f\"Subscribers: {row['Subscribers']:,} | Score: {row['performance_score']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize performance distribution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "# Performance score distribution\n",
    "axes[0, 0].hist(df['performance_score'], bins=30, color='steelblue', edgecolor='black')\n",
    "axes[0, 0].set_xlabel('Performance Score')\n",
    "axes[0, 0].set_ylabel('Number of Videos')\n",
    "axes[0, 0].set_title('Distribution of Video Performance Scores')\n",
    "axes[0, 0].axvline(df['performance_score'].median(), color='red', \n",
    "                   linestyle='--', label='Median')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Views vs Watch Time\n",
    "axes[0, 1].scatter(df['Views'], df['Watch time (hours)'], alpha=0.5)\n",
    "axes[0, 1].set_xlabel('Views')\n",
    "axes[0, 1].set_ylabel('Watch Time (hours)')\n",
    "axes[0, 1].set_title('Views vs Watch Time')\n",
    "\n",
    "# CTR vs Performance Score\n",
    "axes[1, 0].scatter(df['Impressions click-through rate (%)'], \n",
    "                   df['performance_score'], alpha=0.5, color='green')\n",
    "axes[1, 0].set_xlabel('Click-Through Rate (%)')\n",
    "axes[1, 0].set_ylabel('Performance Score')\n",
    "axes[1, 0].set_title('CTR vs Performance Score')\n",
    "\n",
    "# Views per day vs Days since publish\n",
    "axes[1, 1].scatter(df['days_since_publish'], df['views_per_day'], alpha=0.5, color='orange')\n",
    "axes[1, 1].set_xlabel('Days Since Publication')\n",
    "axes[1, 1].set_ylabel('Views Per Day')\n",
    "axes[1, 1].set_title('Video Age vs Daily Views')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. K-Means Clustering Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Select features for clustering\n",
    "clustering_features = [\n",
    "    'Views',\n",
    "    'Watch time (hours)',\n",
    "    'Subscribers',\n",
    "    'Estimated revenue (GBP)',\n",
    "    'Impressions click-through rate (%)',\n",
    "    'avg_view_duration',\n",
    "    'views_per_day',\n",
    "    'subscriber_conversion',\n",
    "    'Duration'\n",
    "]\n",
    "\n",
    "# Prepare data for clustering\n",
    "X = df[clustering_features].copy()\n",
    "\n",
    "# Standardize features\n",
    "scaler_cluster = StandardScaler()\n",
    "X_scaled = scaler_cluster.fit_transform(X)\n",
    "\n",
    "print(f\"Clustering data shape: {X_scaled.shape}\")\n",
    "print(f\"Features used: {clustering_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Determine optimal number of clusters using elbow method\n",
    "inertias = []\n",
    "silhouette_scores = []\n",
    "K_range = range(2, 11)\n",
    "\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(X_scaled)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(X_scaled, kmeans.labels_))\n",
    "\n",
    "# Plot elbow curve\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].plot(K_range, inertias, 'bo-')\n",
    "axes[0].set_xlabel('Number of Clusters (k)')\n",
    "axes[0].set_ylabel('Inertia')\n",
    "axes[0].set_title('Elbow Method for Optimal k')\n",
    "axes[0].grid(True)\n",
    "\n",
    "axes[1].plot(K_range, silhouette_scores, 'ro-')\n",
    "axes[1].set_xlabel('Number of Clusters (k)')\n",
    "axes[1].set_ylabel('Silhouette Score')\n",
    "axes[1].set_title('Silhouette Score for Optimal k')\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find best k based on silhouette score\n",
    "best_k = K_range[np.argmax(silhouette_scores)]\n",
    "print(f\"\\nRecommended number of clusters: {best_k}\")\n",
    "print(f\"Best silhouette score: {max(silhouette_scores):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Perform k-means clustering with optimal k\n",
    "optimal_k = 5  # You can adjust this based on the elbow plot\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "df['cluster'] = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "print(f\"Videos per cluster:\")\n",
    "print(df['cluster'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Analyze cluster characteristics\n",
    "cluster_analysis = df.groupby('cluster')[clustering_features + ['performance_score']].mean()\n",
    "cluster_counts = df['cluster'].value_counts().sort_index()\n",
    "\n",
    "print(\"\\nCluster Characteristics (Average Values):\")\n",
    "print(\"=\"*120)\n",
    "print(cluster_analysis.round(2))\n",
    "\n",
    "# Name clusters based on characteristics\n",
    "cluster_names = {}\n",
    "for cluster_id in range(optimal_k):\n",
    "    cluster_data = cluster_analysis.loc[cluster_id]\n",
    "    \n",
    "    if cluster_data['performance_score'] > 0.5:\n",
    "        if cluster_data['Subscribers'] > cluster_analysis['Subscribers'].median():\n",
    "            cluster_names[cluster_id] = \"ðŸŒŸ Star Performers (High Engagement)\"\n",
    "        else:\n",
    "            cluster_names[cluster_id] = \"ðŸ“ˆ Viral Videos (High Views)\"\n",
    "    elif cluster_data['performance_score'] > 0.3:\n",
    "        cluster_names[cluster_id] = \"âœ… Solid Performers\"\n",
    "    else:\n",
    "        if cluster_data['views_per_day'] < cluster_analysis['views_per_day'].median():\n",
    "            cluster_names[cluster_id] = \"ðŸ“‰ Underperformers\"\n",
    "        else:\n",
    "            cluster_names[cluster_id] = \"ðŸ”„ Growing Videos\"\n",
    "\n",
    "df['cluster_name'] = df['cluster'].map(cluster_names)\n",
    "\n",
    "print(\"\\n\\nCluster Names and Sizes:\")\n",
    "for cluster_id, name in cluster_names.items():\n",
    "    count = cluster_counts[cluster_id]\n",
    "    print(f\"Cluster {cluster_id}: {name} ({count} videos)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize clusters using PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "df['pca1'] = X_pca[:, 0]\n",
    "df['pca2'] = X_pca[:, 1]\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A', '#98D8C8']\n",
    "\n",
    "for cluster_id in range(optimal_k):\n",
    "    cluster_data = df[df['cluster'] == cluster_id]\n",
    "    plt.scatter(cluster_data['pca1'], cluster_data['pca2'], \n",
    "                c=colors[cluster_id], label=cluster_names[cluster_id],\n",
    "                alpha=0.6, s=100, edgecolors='black', linewidth=0.5)\n",
    "\n",
    "plt.xlabel(f'First Principal Component ({pca.explained_variance_ratio_[0]:.1%} variance)')\n",
    "plt.ylabel(f'Second Principal Component ({pca.explained_variance_ratio_[1]:.1%} variance)')\n",
    "plt.title('Video Clusters Visualization (PCA Projection)')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Cluster Deep Dive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Analyze each cluster in detail\n",
    "for cluster_id in range(optimal_k):\n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(f\"Cluster {cluster_id}: {cluster_names[cluster_id]}\")\n",
    "    print(f\"{'='*100}\")\n",
    "    \n",
    "    cluster_videos = df[df['cluster'] == cluster_id].copy()\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(f\"\\nNumber of videos: {len(cluster_videos)}\")\n",
    "    print(f\"Average performance score: {cluster_videos['performance_score'].mean():.3f}\")\n",
    "    print(f\"Average views: {cluster_videos['Views'].mean():,.0f}\")\n",
    "    print(f\"Average watch time: {cluster_videos['Watch time (hours)'].mean():.1f} hours\")\n",
    "    print(f\"Average CTR: {cluster_videos['Impressions click-through rate (%)'].mean():.2f}%\")\n",
    "    \n",
    "    # Top keywords in this cluster\n",
    "    cluster_keywords = []\n",
    "    for keywords in cluster_videos['keywords']:\n",
    "        cluster_keywords.extend(keywords)\n",
    "    \n",
    "    cluster_keyword_counts = Counter(cluster_keywords)\n",
    "    print(f\"\\nTop keywords in this cluster:\")\n",
    "    for keyword, count in cluster_keyword_counts.most_common(10):\n",
    "        print(f\"  - {keyword}: {count}\")\n",
    "    \n",
    "    # Sample videos\n",
    "    print(f\"\\nSample videos from this cluster:\")\n",
    "    sample = cluster_videos.nlargest(3, 'Views')[['Video title', 'Views', 'performance_score']]\n",
    "    for idx, row in sample.iterrows():\n",
    "        print(f\"  â€¢ {row['Video title'][:70]}\")\n",
    "        print(f\"    Views: {row['Views']:,} | Score: {row['performance_score']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Success Factor Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Correlation analysis\n",
    "correlation_features = [\n",
    "    'Views', 'Watch time (hours)', 'Subscribers', \n",
    "    'Estimated revenue (GBP)', 'Impressions click-through rate (%)',\n",
    "    'avg_view_duration', 'views_per_day', 'Duration', 'performance_score'\n",
    "]\n",
    "\n",
    "correlation_matrix = df[correlation_features].corr()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            center=0, square=True, linewidths=1)\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nStrongest correlations with performance score:\")\n",
    "perf_correlations = correlation_matrix['performance_score'].sort_values(ascending=False)[1:]\n",
    "for feature, corr in perf_correlations.items():\n",
    "    print(f\"  {feature}: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Analyze impact of top keywords on performance\n",
    "keyword_impact = {}\n",
    "for keyword in top_keywords:\n",
    "    has_keyword = df[df[f'has_{keyword}'] == 1]['performance_score'].mean()\n",
    "    no_keyword = df[df[f'has_{keyword}'] == 0]['performance_score'].mean()\n",
    "    keyword_impact[keyword] = has_keyword - no_keyword\n",
    "\n",
    "keyword_impact_df = pd.DataFrame(list(keyword_impact.items()), \n",
    "                                  columns=['Keyword', 'Performance Impact'])\n",
    "keyword_impact_df = keyword_impact_df.sort_values('Performance Impact', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "colors = ['green' if x > 0 else 'red' for x in keyword_impact_df['Performance Impact']]\n",
    "plt.barh(keyword_impact_df['Keyword'], keyword_impact_df['Performance Impact'], color=colors)\n",
    "plt.xlabel('Performance Impact (Difference in Average Score)')\n",
    "plt.title('Keyword Impact on Video Performance')\n",
    "plt.axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKeywords with highest positive impact:\")\n",
    "print(keyword_impact_df.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Trending Topics Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Analyze performance of trending keywords\n",
    "trending_keyword_performance = {}\n",
    "\n",
    "for keyword, _ in trending_keywords[:15]:\n",
    "    # Get videos with this keyword\n",
    "    videos_with_keyword = df[df['keywords'].apply(lambda x: keyword in x)]\n",
    "    \n",
    "    if len(videos_with_keyword) > 0:\n",
    "        avg_perf = videos_with_keyword['performance_score'].mean()\n",
    "        avg_views = videos_with_keyword['Views'].mean()\n",
    "        count = len(videos_with_keyword)\n",
    "        \n",
    "        trending_keyword_performance[keyword] = {\n",
    "            'avg_performance': avg_perf,\n",
    "            'avg_views': avg_views,\n",
    "            'video_count': count\n",
    "        }\n",
    "\n",
    "trending_perf_df = pd.DataFrame(trending_keyword_performance).T\n",
    "trending_perf_df = trending_perf_df.sort_values('avg_performance', ascending=False)\n",
    "\n",
    "print(\"\\nTrending Keywords Performance Analysis:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Keyword':<20} {'Avg Performance':<18} {'Avg Views':<15} {'Video Count'}\")\n",
    "print(\"=\"*80)\n",
    "for keyword, row in trending_perf_df.iterrows():\n",
    "    print(f\"{keyword:<20} {row['avg_performance']:<18.3f} {row['avg_views']:<15,.0f} {row['video_count']:.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create a scatter plot of trending keywords\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "scatter = plt.scatter(trending_perf_df['avg_views'], \n",
    "                      trending_perf_df['avg_performance'],\n",
    "                      s=trending_perf_df['video_count']*50,\n",
    "                      alpha=0.6, c=range(len(trending_perf_df)), cmap='viridis',\n",
    "                      edgecolors='black', linewidth=1)\n",
    "\n",
    "# Add labels\n",
    "for keyword, row in trending_perf_df.iterrows():\n",
    "    plt.annotate(keyword, \n",
    "                 (row['avg_views'], row['avg_performance']),\n",
    "                 xytext=(5, 5), textcoords='offset points',\n",
    "                 fontsize=9, alpha=0.8)\n",
    "\n",
    "plt.xlabel('Average Views')\n",
    "plt.ylabel('Average Performance Score')\n",
    "plt.title('Trending Keywords: Performance vs Views (bubble size = video count)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Recommendations and Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"KEY INSIGHTS AND RECOMMENDATIONS\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# 1. Best performing cluster\n",
    "best_cluster = cluster_analysis['performance_score'].idxmax()\n",
    "print(f\"\\n1. BEST PERFORMING CLUSTER: {cluster_names[best_cluster]}\")\n",
    "print(f\"   - Average performance score: {cluster_analysis.loc[best_cluster, 'performance_score']:.3f}\")\n",
    "print(f\"   - Average views: {cluster_analysis.loc[best_cluster, 'Views']:,.0f}\")\n",
    "print(f\"   - Average CTR: {cluster_analysis.loc[best_cluster, 'Impressions click-through rate (%)']:.2f}%\")\n",
    "\n",
    "# 2. Top keywords to focus on\n",
    "print(\"\\n2. HIGH-IMPACT KEYWORDS TO FOCUS ON:\")\n",
    "top_impact_keywords = keyword_impact_df.head(5)\n",
    "for _, row in top_impact_keywords.iterrows():\n",
    "    print(f\"   - {row['Keyword']}: +{row['Performance Impact']:.3f} impact\")\n",
    "\n",
    "# 3. Trending topics\n",
    "print(\"\\n3. TRENDING TOPICS (Most Popular Recently):\")\n",
    "for keyword, score in trending_keywords[:5]:\n",
    "    print(f\"   - {keyword}: Trending score {score:.2f}\")\n",
    "\n",
    "# 4. Success factors\n",
    "print(\"\\n4. KEY SUCCESS FACTORS (Strongest Correlations with Performance):\")\n",
    "top_correlations = perf_correlations.head(5)\n",
    "for feature, corr in top_correlations.items():\n",
    "    print(f\"   - {feature}: {corr:.3f} correlation\")\n",
    "\n",
    "# 5. Improvement opportunities\n",
    "worst_cluster = cluster_analysis['performance_score'].idxmin()\n",
    "print(f\"\\n5. IMPROVEMENT OPPORTUNITIES: {cluster_names[worst_cluster]}\")\n",
    "print(f\"   - Number of videos: {cluster_counts[worst_cluster]}\")\n",
    "print(f\"   - Average performance: {cluster_analysis.loc[worst_cluster, 'performance_score']:.3f}\")\n",
    "print(f\"   - Consider improving: CTR, watch time, and thumbnail quality\")\n",
    "\n",
    "# 6. Optimal video characteristics\n",
    "top_performers = df.nlargest(20, 'performance_score')\n",
    "print(\"\\n6. OPTIMAL VIDEO CHARACTERISTICS (Based on Top 20 Performers):\")\n",
    "print(f\"   - Average duration: {top_performers['Duration'].mean()/60:.1f} minutes\")\n",
    "print(f\"   - Average CTR: {top_performers['Impressions click-through rate (%)'].mean():.2f}%\")\n",
    "print(f\"   - Average watch time per view: {top_performers['avg_view_duration'].mean():.1f} minutes\")\n",
    "print(f\"   - Average subscriber conversion: {top_performers['subscriber_conversion'].mean():.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Export results\n",
    "output_df = df[['Video title', 'Views', 'Watch time (hours)', 'Subscribers', \n",
    "                'Estimated revenue (GBP)', 'performance_score', 'cluster', \n",
    "                'cluster_name', 'keyword_string']].copy()\n",
    "\n",
    "output_df.to_csv('youtube_analysis_results.csv', index=False)\n",
    "print(\"\\n\\nResults exported to 'youtube_analysis_results.csv'\")\n",
    "\n",
    "# Export cluster summary\n",
    "cluster_summary = cluster_analysis.copy()\n",
    "cluster_summary['cluster_name'] = cluster_summary.index.map(cluster_names)\n",
    "cluster_summary['video_count'] = cluster_counts\n",
    "cluster_summary.to_csv('cluster_summary.csv')\n",
    "print(\"Cluster summary exported to 'cluster_summary.csv'\")\n",
    "\n",
    "# Export trending keywords\n",
    "trending_df = pd.DataFrame(trending_keywords, columns=['Keyword', 'Trending Score'])\n",
    "trending_df.to_csv('trending_keywords.csv', index=False)\n",
    "print(\"Trending keywords exported to 'trending_keywords.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook has analyzed your YouTube video performance using k-means clustering and provided:\n",
    "\n",
    "1. **Performance Classification**: Videos grouped into distinct performance clusters\n",
    "2. **Best/Worst Performers**: Clear identification of top and bottom videos\n",
    "3. **Success Factors**: Key metrics correlated with high performance\n",
    "4. **Trending Keywords**: Topics gaining popularity in recent months\n",
    "5. **Keyword Impact**: Which keywords in titles correlate with better performance\n",
    "6. **Actionable Recommendations**: Data-driven suggestions for content strategy\n",
    "\n",
    "The exported CSV files contain detailed results for further analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
